{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "43923fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment ready (patched is_mixed if needed)\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import discopy\n",
    "\n",
    "# Patch missing .is_mixed (for lambeq + newer discopy)\n",
    "if not hasattr(getattr(discopy, \"monoidal\", None).Diagram, \"is_mixed\"):\n",
    "    discopy.monoidal.Diagram.is_mixed = property(lambda self: False)\n",
    "\n",
    "print(\"✅ Environment ready (patched is_mixed if needed)\")\n",
    "\n",
    "from lambeq import AtomicType\n",
    "\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "P = AtomicType.PREPOSITIONAL_PHRASE\n",
    "CONJ = AtomicType.CONJUNCTION\n",
    "PUNCT = AtomicType.PUNCTUATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import AtomicType\n",
    "from lambeq import IQPAnsatz\n",
    "\n",
    "# Example: noun → 1 qubit, sentence → 1 qubit\n",
    "ob_map = dict({\n",
    "    N: 2,\n",
    "    S: 1,\n",
    "    P: 0,\n",
    "    CONJ: 1,\n",
    "    PUNCT: 0\n",
    "})\n",
    "\n",
    "ansatz = IQPAnsatz(ob_map, n_layers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0a395963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 404 sentences.\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "def load_data(csv_file, sample_fraction=1.0):\n",
    "    \"\"\"Loads Question Pairs from a CSV file\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to csv_file\n",
    "        sample_fraction (float): Fraction of data to sample, default is 1.0\n",
    "    Returns:\n",
    "        tuple: A tuple containing supervised data pairs\n",
    "        returns [],[] on error\n",
    "    \"\"\"\n",
    "    sentences1 = []\n",
    "    sentences2 = []\n",
    "    is_duplicate = []\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8')\n",
    "        #print(\"Column names:\", df.columns)\n",
    "        \n",
    "        if sample_fraction < 1.0:\n",
    "            df = df.sample(frac=sample_fraction, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        sentence1_series = df['question1']\n",
    "        sentence2_series = df['question2']\n",
    "        is_duplicate_series = df['is_duplicate']\n",
    "        \n",
    "        sentences1 = sentence1_series.tolist()\n",
    "        sentences2 = sentence2_series.tolist()\n",
    "        is_duplicate = is_duplicate_series.tolist()\n",
    "        \n",
    "        if len(sentences1) != len(sentences2):\n",
    "            raise ValueError(\"The number of sentences in question1 and question2 do not match.\")\n",
    "        else:\n",
    "            print(f\"Loaded {len(sentences1)} sentences.\")\n",
    "        return sentences1, sentences2, is_duplicate\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Wrong Path\")\n",
    "        return [],[],[]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An {e} Error Occurred\")\n",
    "        return [],[],[]\n",
    "\n",
    "DATA_PATH = r'C:/Users/Jash\\Documents/Research\\Semantic Equivilance\\SemanticEquivilance/question_pairs/questions.csv'\n",
    "sentences1, sentences2, value = load_data(DATA_PATH, sample_fraction=0.001)\n",
    "data_pairs = list(zip(sentences1, sentences2, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7815b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "from lambeq import AtomicType, BobcatParser, StronglyEntanglingAnsatz, Rewriter, IQPAnsatz, SpacyTokeniser, TensorAnsatz\n",
    "\n",
    "def swap_test(state1_vec, state2_vec, num_qubits, initial_state=0):\n",
    "    \"\"\"\n",
    "    Performs a Quantum Swap Test between two quantum state vectors.\n",
    "\n",
    "    Args:\n",
    "        state1_vec (np.ndarray): The first state vector.\n",
    "        state2_vec (np.ndarray): The second state vector.\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated squared overlap (fidelity) between the two states.\n",
    "    \"\"\"\n",
    "    if 2**num_qubits != len(state1_vec):\n",
    "        raise ValueError(\"State vectors must have a length that is a power of 2.\")\n",
    "\n",
    "    total_qubits = 1 + 2 * num_qubits #1 Ancilla qubit + 2 state qubits\n",
    "\n",
    "    dev = qml.device(\"lightning.gpu\", wires=total_qubits, shots=10000) # N = 10000 runs of the circuit for statistical significance\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(): #|0 , psi, phi>\n",
    "        # Step 1: Prepare the ancilla qubit in a superposition\n",
    "        qml.Hadamard(wires=0)\n",
    "        print(f\"Comparing: {state1_vec} and {state2_vec}\")\n",
    "        # Step 2: Prepare the two input states\n",
    "        #basis for protocol 1\n",
    "        qml.StatePrep(state1_vec, wires=range(1, 1 + num_qubits), normalize=True)\n",
    "        #basis for protocol 1\n",
    "        qml.StatePrep(state2_vec, wires=range(1 + num_qubits, 1 + 2 * num_qubits))\n",
    "\n",
    "        # Step 3: Apply controlled-SWAP gates\n",
    "        for i in range(num_qubits):\n",
    "            qml.CSWAP(wires=[0, 1 + i, 1 + num_qubits + i]) #selects every register of phi and psi for swap\n",
    "\n",
    "        # Step 4: Apply Hadamard to ancilla\n",
    "        qml.Hadamard(wires=0)\n",
    "        # Step 5: Measure the ancilla qubit\n",
    "        return qml.sample(wires=0)\n",
    "\n",
    "    measurement_results = circuit()\n",
    "    squared_overlap = 1 - 2/len(measurement_results) * np.sum(measurement_results)\n",
    "    \n",
    "    return abs(squared_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from lambeq.backend.pennylane import to_pennylane as to_qml\n",
    "def lambeq_sentence_to_circuit(sentence, Tokeniser, ansatz, parser, rewriter, return_type='state', include_debug_prints=False, expval = qml.PauliZ(0), target_qubits=None):\n",
    "    \"\"\"\n",
    "    Converts a natural language sentence into a quantum state vector\n",
    "    using Lambeq's BobcatParser and IQPAnsatz, handling parameterization\n",
    "    via PennyLaneModel.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        ansatz (lambeq.ansatz.Ansatz): The quantum ansatz to apply.\n",
    "        parser (lambeq.parser.Parser): The parser to convert sentence to diagram. This is a GPT\n",
    "        rewriter (lambeq.rewrite.Rewriter): The rewriter to simplify the diagram. This is a GPT\n",
    "        include_debug_prints (bool): Whether to include detailed debug prints.\n",
    "        start_basis_state (int): The basis state to initialize the qubits. Default is |0>.\n",
    "        seed (int, optional): Seed for random number generation for reproducibility.\n",
    "        return_type (str): 'state' or 'expval' to specify the return type.\n",
    "        expval (qml.Observable): The observable for expval value calculation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the state vector (np.ndarray) and\n",
    "               the number of qubits (int).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if include_debug_prints:\n",
    "            print(f\"\\n--- Debugging: Sentence '{sentence}' ---\")\n",
    "        # Step 0: Tokenize the sentence\n",
    "        tokens = Tokeniser.tokenise_sentence(sentence) # Not optional for non-clean inputs\n",
    "        \n",
    "        # Step 1: Convert sentence to a DisCoPy diagram\n",
    "        diagram = parser.sentence2diagram(tokens, tokenised=True)\n",
    "        if include_debug_prints:\n",
    "            print(\"Step 1: Sentence parsed to diagram.\")\n",
    "\n",
    "        # Step 2: Rewrite the diagram\n",
    "        rewritten_diagram = rewriter(diagram)\n",
    "        if include_debug_prints:\n",
    "            print(\"Step 2: Diagram rewritten.\")\n",
    "\n",
    "        # Step 3: Normalize the diagram\n",
    "        normalized_diagram = rewritten_diagram.normal_form()\n",
    "        if include_debug_prints:\n",
    "            print(\"Step 3: Diagram normalized.\")\n",
    "            \n",
    "        # Step 4: Apply the ansatz to the normalized diagram to get a DisCoPy circuit\n",
    "        circuit = ansatz(normalized_diagram)\n",
    "        if include_debug_prints:\n",
    "            print(\"Step 4: Ansatz applied to create DisCoPy circuit.\")\n",
    "\n",
    "        # Step 5: Convert the DisCoPy circuit to a PennyLane circuit object\n",
    "        temp_qml_circuit = to_qml(circuit)\n",
    "        \n",
    "        num_qubits = temp_qml_circuit._n_qubits\n",
    "        param_structure = temp_qml_circuit._params\n",
    "        device_qubits = target_qubits if target_qubits is not None and target_qubits >= num_qubits else num_qubits\n",
    "        \n",
    "        if include_debug_prints:\n",
    "            print(\"Step 5: DisCoPy circuit converted to PennyLane object.\")\n",
    "            print(f\"Parameter structure: {param_structure}\")\n",
    "            print(f\"Number of qubits: {num_qubits}, Device Wires: {device_qubits}\")\n",
    "        \n",
    "        # Build parameters in the exact same structure as _params\n",
    "        structured_params = []\n",
    "            \n",
    "        if include_debug_prints:\n",
    "            print(\"Step 6: Structured parameters generated.\")\n",
    "            \n",
    "        dev = qml.device(\"lightning.gpu\", wires=num_qubits, shots=10000) # N = 10000 runs of the circuit for statistical significance\n",
    "        \n",
    "        @qml.qnode(dev)\n",
    "        def qnode_circuit(structured_params):\n",
    "            circuit_func = temp_qml_circuit.make_circuit()\n",
    "            circuit_func(structured_params)\n",
    "            if return_type == 'expval':\n",
    "                return qml.expval(expval)\n",
    "            else:\n",
    "                return qml.state()  # Return the state vector after applying the circuit\n",
    "        \n",
    "        return qnode_circuit, param_structure, device_qubits\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: Failed to process circuit: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f02b4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def initialize_structured_params(param_structure, sentence_seed=None):\n",
    "    \"\"\"\n",
    "    Initializes structured parameters based on the given parameter structure.\n",
    "\n",
    "    Args:\n",
    "        param_structure (list): The structure of parameters as a list of lists.\n",
    "        seed (int): Seed for random number generation for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of structured parameters with random values.\n",
    "    \"\"\"\n",
    "    if sentence_seed is not None:\n",
    "        random.seed(sentence_seed)\n",
    "    structured_params = []\n",
    "    for param_group in param_structure:\n",
    "        if isinstance(param_group, list) and len(param_group) > 0:\n",
    "            # This parameter group has parameters - create random values for each\n",
    "            group_values = [random.uniform(0.1, 2 * np.pi - 0.1) for _ in param_group]\n",
    "            structured_params.append(group_values)\n",
    "        else:\n",
    "            # Empty parameter group\n",
    "            structured_params.append([])\n",
    "    \n",
    "    return structured_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5b3256c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def FischerInformation(Fidelity): #Statisitcal Information and DISTANCE metric Fubini-Study Metric/ Wooters Distance\n",
    "    rootFidelity = math.sqrt(Fidelity) #Square root fidelity term\n",
    "    return math.acos(rootFidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(overlap, is_duplicate):\n",
    "    \"\"\"\n",
    "    Revised loss function based on the overlap and a binary label.\n",
    "    - For duplicates (is_duplicate=1), minimizes loss by driving overlap to 1.\n",
    "    - For non-duplicates (is_duplicate=0), minimizes loss by reducing the overlap.\n",
    "    \"\"\"\n",
    "    if is_duplicate == 1:\n",
    "        # A duplicate pair should have an overlap of 1 (Quantum Angle = 0) Mean Squared Error\n",
    "        return (1 - overlap)**2\n",
    "    else:\n",
    "        # MSE for non-duplicate pairs\n",
    "        return (overlap)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "aab15ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(qnode_func, params1, params2):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between two quantum states prepared by the same QNode\n",
    "    but with different parameters. This is a shortcut that only works with quantum simulators, for real quantum hardware, use the swap test function.\n",
    "\n",
    "    Args:\n",
    "        qnode_func (qml.QNode): The quantum circuit QNode.\n",
    "        params1 (list): Structured parameters for the first state.\n",
    "        params2 (list): Structured parameters for the second state.\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated squared overlap (fidelity) between the two states.\n",
    "    \"\"\"\n",
    "    # Get the state vectors for both sets of parameters\n",
    "    state1 = qnode_func(params1)\n",
    "    state2 = qnode_func(params2)\n",
    "    \n",
    "    # Calculate the overlap\n",
    "    overlap = np.abs(np.vdot(state1, state2))**2\n",
    "    \n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to group sentences by qubit count\n",
    "def calculate_pair_gradients(qnode_func, params, s1, s2, is_duplicate):\n",
    "    \"\"\"\n",
    "    Calculates gradients for a pair of sentences with respect to the shared parameters.\n",
    "    Returns a dictionary of gradients indexed by (group, element) tuple.\n",
    "    \"\"\"\n",
    "    gradients = {idx: 0.0 for idx in [(g, e) for g in range(len(params)) for e in range(len(params[g]))]}\n",
    "\n",
    "    # We need to compute the gradient for each parameter\n",
    "    for group_idx, group in enumerate(params):\n",
    "        for elem_idx in range(len(group)):\n",
    "            param_index = (group_idx, elem_idx)\n",
    "\n",
    "            # Shift the parameters for both sentences in the pair\n",
    "            params_plus_s1 = params.copy()\n",
    "            params_plus_s1[group_idx][elem_idx] += np.pi / 2\n",
    "            \n",
    "            params_minus_s1 = params.copy()\n",
    "            params_minus_s1[group_idx][elem_idx] -= np.pi / 2\n",
    "\n",
    "            # Overlap for shifted s1\n",
    "            overlap_plus = calculate_overlap(qnode_func, params_plus_s1, params)\n",
    "            overlap_minus = calculate_overlap(qnode_func, params_minus_s1, params)\n",
    "\n",
    "            # Gradient contribution from S1\n",
    "            grad_s1 = (loss_function(overlap_plus, is_duplicate) - loss_function(overlap_minus, is_duplicate)) / 2\n",
    "\n",
    "            # Now, shift the parameters for the second sentence (S2)\n",
    "            params_plus_s2 = params.copy()\n",
    "            params_plus_s2[group_idx][elem_idx] += np.pi / 2\n",
    "            \n",
    "            params_minus_s2 = params.copy()\n",
    "            params_minus_s2[group_idx][elem_idx] -= np.pi / 2\n",
    "\n",
    "            # Overlap for shifted S2\n",
    "            overlap_plus_2 = calculate_overlap(qnode_func, params, params_plus_s2)\n",
    "            overlap_minus_2 = calculate_overlap(qnode_func, params, params_minus_s2)\n",
    "\n",
    "            # Gradient contribution from S2\n",
    "            grad_s2 = (loss_function(overlap_plus_2, is_duplicate) - loss_function(overlap_minus_2, is_duplicate)) / 2\n",
    "            \n",
    "            # The total gradient is the sum of contributions from both states\n",
    "            gradients[param_index] = grad_s1 + grad_s2\n",
    "\n",
    "    return gradients\n",
    "\n",
    "def group_sentences_by_qubit_count(sentences, Tokeniser, ansatz, parser, rewriter):\n",
    "    \"\"\"\n",
    "    Groups sentences based on the number of qubits in their corresponding circuit.\n",
    "    \n",
    "    Returns a dictionary where keys are qubit counts and values are lists of sentences.\n",
    "    \"\"\"\n",
    "    print(\"Grouping sentences by qubit count...\")\n",
    "    grouped_sentences = {}\n",
    "    for sentence in sentences:\n",
    "        try:\n",
    "            tokens = Tokeniser.tokenize(sentence)\n",
    "            diagram = parser.sentence2diagram(tokens, tokenised=True)\n",
    "            rewritten_diagram = rewriter(diagram)\n",
    "            normalized_diagram = rewritten_diagram.normal_form()\n",
    "            circuit = ansatz(normalized_diagram)\n",
    "\n",
    "            # --- CORRECTION: Get the number of qubits from the circuit object directly ---\n",
    "            temp_qml_circuit = to_qml(circuit)\n",
    "            num_qubits = temp_qml_circuit._n_qubits\n",
    "            \n",
    "            if num_qubits not in grouped_sentences:\n",
    "                grouped_sentences[num_qubits] = []\n",
    "                \n",
    "            grouped_sentences[num_qubits].append(sentence)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping sentence '{sentence}' due to an error: {e}\")\n",
    "\n",
    "    print(\"Grouping complete.\")\n",
    "    for n_qubits, s_list in grouped_sentences.items():\n",
    "        print(f\"  - {n_qubits} qubits: {len(s_list)} sentences\")\n",
    "        \n",
    "    return grouped_sentences\n",
    "\n",
    "# Assuming all other helper functions are defined as per previous responses\n",
    "\n",
    "def main_workflow(data_pairs, parser, rewriter, ansatz, Tokeniser):\n",
    "    \"\"\"\n",
    "    The main function to perform per-dimension training based on sentence pairs.\n",
    "    \n",
    "    Args:\n",
    "        data_pairs (list): A list of tuples, each containing (sentence1, sentence2, is_duplicate).\n",
    "        parser (lambeq.parser.Parser): The parser.\n",
    "        rewriter (lambeq.rewriter.Rewriter): The rewriter.\n",
    "        ansatz (lambeq.ansatz.Ansatz): The quantum ansatz.\n",
    "    \"\"\"\n",
    "    print(\"Grouping sentence pairs by qubit count...\")\n",
    "    grouped_pairs = {}\n",
    "    # Preprocess all data\n",
    "    print(\"Preprocessing sentence pairs to determine qubit counts...\")\n",
    "    preprocessed_pairs = []\n",
    "    for s1, s2, is_duplicate in data_pairs:\n",
    "        try:\n",
    "            _, _, num_qubits_s1 = lambeq_sentence_to_circuit(s1, Tokeniser, ansatz, parser, rewriter, return_type='state')\n",
    "            _, _, num_qubits_s2 = lambeq_sentence_to_circuit(s2, Tokeniser, ansatz, parser, rewriter, return_type='state')\n",
    "            preprocessed_pairs.append((s1, s2, is_duplicate, num_qubits_s1, num_qubits_s2))\n",
    "            \n",
    "           # if num_qubits_s1 is None or num_qubits_s2 is None or num_qubits_s1 != num_qubits_s2:\n",
    "           #     print(f\"Skipping pair ('{s1}', '{s2}') due to different or invalid qubit counts.\")\n",
    "           #     continue   ### I used this line previously, but this should be a part of the loss function\n",
    "\n",
    "            if num_qubits_s1 not in grouped_pairs:\n",
    "                grouped_pairs[num_qubits_s1] = []\n",
    "\n",
    "            grouped_pairs[num_qubits_s1].append((s1, s2, is_duplicate))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping pair due to an error: {e}\")\n",
    "\n",
    "    print(\"Grouping complete.\")\n",
    "    for n_qubits, s_list in grouped_pairs.items():\n",
    "        print(f\"  - {n_qubits} qubits: {len(s_list)} sentence pairs\")\n",
    "        \n",
    "    trained_params = {}\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "    \n",
    "    for num_qubits, pair_list in grouped_pairs.items():\n",
    "        if not pair_list:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nTraining model for {num_qubits} qubits with {len(pair_list)} pairs...\")\n",
    "        \n",
    "        # Get the blueprint for the circuit and parameters\n",
    "        rep_sentence = pair_list[0][0]\n",
    "        qnode_func, param_structure, _ = lambeq_sentence_to_circuit(\n",
    "            rep_sentence, Tokeniser, ansatz, parser, rewriter, return_type='expval', expval=qml.PauliZ(0)\n",
    "        )\n",
    "        \n",
    "        # Initialize a single set of parameters for this dimension\n",
    "        params = initialize_structured_params(param_structure)\n",
    "        \n",
    "        # --- Training loop over pairs ---\n",
    "        learning_rate = 0.01\n",
    "        for s1, s2, is_duplicate in pair_list:\n",
    "            \n",
    "            gradients = calculate_pair_gradients(qnode_func, params, s1, s2, is_duplicate)\n",
    "            \n",
    "            for group_idx, group in enumerate(params):\n",
    "                for elem_idx in range(len(group)):\n",
    "                    param_index = (group_idx, elem_idx)\n",
    "                    params[group_idx][elem_idx] -= learning_rate * gradients[param_index]\n",
    "            \n",
    "        trained_params[num_qubits] = params\n",
    "    \n",
    "    print(\"\\n--- Training Complete ---\")\n",
    "    \n",
    "    print(\"\\n--- Performing Final Swap Tests with Trained Parameters ---\")\n",
    "    for num_qubits, pair_list in grouped_pairs.items():\n",
    "        if not pair_list:\n",
    "            continue\n",
    "        \n",
    "        sample_pairs = pair_list[:5] if len(pair_list) > 5 else pair_list\n",
    "        \n",
    "        for s1, s2, is_duplicate in sample_pairs:\n",
    "            print(f\"\\nEvaluating Pair: '{s1}' vs. '{s2}' (Label: {'Duplicate' if is_duplicate else 'Not Duplicate'})\")\n",
    "            \n",
    "            optimized_params = trained_params[num_qubits]\n",
    "            \n",
    "            qnode_for_state, _, _ = lambeq_sentence_to_circuit(\n",
    "                s1, Tokeniser, ansatz, parser, rewriter, return_type='state'\n",
    "            )\n",
    "            vec1 = qnode_for_state(optimized_params)\n",
    "            \n",
    "            qnode_for_state_2, _, _ = lambeq_sentence_to_circuit(\n",
    "                s2, Tokeniser, ansatz, parser, rewriter, return_type='state'\n",
    "            )\n",
    "            vec2 = qnode_for_state_2(optimized_params)\n",
    "\n",
    "            overlap = swap_test(vec1, vec2, num_qubits)\n",
    "            print(f\"Final Overlap: {overlap:.4f}\")\n",
    "            Qangle = FischerInformation(overlap)\n",
    "            NormalizedQangle = Qangle / (math.pi / 2)\n",
    "            print(f\"Estimated Quantum Angle: {NormalizedQangle:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e2e208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating states from sentences ---\n",
      "Error processing sentence 'Alice loves the dog that Bob purchased.': too many values to unpack (expected 2)\n",
      "Error processing sentence 'Bob loves the dog that Alice sold.': too many values to unpack (expected 2)\n",
      "Error processing sentence 'The big cat sleeps peacefully.': too many values to unpack (expected 2)\n",
      "Error processing sentence 'The small bird sings loudly.': too many values to unpack (expected 2)\n",
      "Error processing sentence 'The lizard basks in the sun.': too many values to unpack (expected 2)\n",
      "Error processing sentence 'The sun shines on the lizard': too many values to unpack (expected 2)\n",
      "\n",
      "--- Performing Swap Tests ---\n",
      "No valid multi-qubit states generated. Cannot perform Swap Tests meaningfully.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "if __name__ == \"__main__\":\n",
    "    spacy.load('en_core_web_sm')\n",
    "    Tokeniser = SpacyTokeniser()\n",
    "    parser = BobcatParser()\n",
    "    rewriter = Rewriter(['curry', 'prepositional_phrase', 'determiner'])\n",
    "    # Increase ansatz parameters to get more complex quantum states\n",
    "    # ansatz = StronglyEntanglingAnsatz(\n",
    "    # {AtomicType.NOUN: 2, AtomicType.SENTENCE: 1}, \n",
    "    # n_layers=1\n",
    "    ansatz = IQPAnsatz({AtomicType.NOUN: 2, AtomicType.SENTENCE: 1, AtomicType.CONJUNCTION: 1}, n_layers=1\n",
    ")\n",
    "\n",
    "    print(\"--- Generating states from sentences ---\")\n",
    "\n",
    "    sentence1 = \"Alice loves the dog that Bob purchased.\"\n",
    "    sentence2 = \"Bob loves the dog that Alice sold.\"\n",
    "    sentence3 = \"The big cat sleeps peacefully.\"\n",
    "    sentence4 = \"The small bird sings loudly.\"\n",
    "    sentence5 = \"The lizard basks in the sun.\"\n",
    "    sentence6 = \"The sun shines on the lizard\"\n",
    "    \n",
    "    sentences = [sentence1, sentence2, sentence3, sentence4, sentence5, sentence6]\n",
    "    state_data = {}\n",
    "    for s_idx, sentence in enumerate(sentences):\n",
    "        try:\n",
    "            state_vec, num_qubits = lambeq_sentence_to_circuit(sentence, Tokeniser, ansatz, parser, rewriter)\n",
    "            #state_vec, num_qubits = lambeq_sentence_to_state_vector(sentence, ansatz, parser, rewriter, include_debug_prints=False)\n",
    "            state_data[sentence] = (state_vec, num_qubits)\n",
    "            print(f\"Sentence {s_idx+1}: '{sentence}'\")\n",
    "            print(f\"Generated state with {num_qubits} qubits\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sentence '{sentence}': {e}\")\n",
    "            state_data[sentence] = (None, None)\n",
    "\n",
    "    print(\"\\n--- Performing Swap Tests ---\")\n",
    "    \n",
    "    # Filter out sentences that did not produce valid states\n",
    "    valid_sentences = [s for s in sentences if state_data[s][0] is not None and state_data[s][1] is not None and state_data[s][1] > 0]\n",
    "\n",
    "    if not valid_sentences:\n",
    "        print(\"No valid multi-qubit states generated. Cannot perform Swap Tests meaningfully.\")\n",
    "    else:\n",
    "        first_num_qubits = state_data[valid_sentences[0]][1]\n",
    "        all_same_qubits = all(state_data[s][1] == first_num_qubits for s in valid_sentences)\n",
    "\n",
    "        if not all_same_qubits:\n",
    "            print(\"\\nWarning: Not all valid sentences resulted in circuits with the same number of qubits.\")\n",
    "            print(\"Swap Test requires states to have the same number of qubits.\")\n",
    "            print(\"Pairs with different qubit counts will be skipped.\")\n",
    "            for s in valid_sentences:\n",
    "                print(f\"  '{s}': {state_data[s][1]} qubits\")\n",
    "\n",
    "        for i in range(len(valid_sentences)):\n",
    "            for j in range(i, len(valid_sentences)):\n",
    "                s1 = valid_sentences[i]\n",
    "                s2 = valid_sentences[j]\n",
    "\n",
    "                vec1, nq1 = state_data[s1]\n",
    "                vec2, nq2 = state_data[s2]\n",
    "\n",
    "                if nq1 == nq2:\n",
    "                    print(f\"\\nSwap Test between '{s1}' and '{s2}':\")\n",
    "                    # Fix: Use nq1 (or nq2, they're equal)\n",
    "                    overlap = swap_test(vec1, vec2, nq1)\n",
    "                    print(overlap)\n",
    "                    Qangle = FischerInformation(overlap) # 0 - pi/2\n",
    "                    \n",
    "                    print(f\"Estimated Quantum Angle: {Qangle:.4f}\")\n",
    "                    if s1 == s2:\n",
    "                        print(\" (Expected to be close to 1.0 for identical states)\")\n",
    "                else:\n",
    "                    print(f\"\\nSkipping Swap Test between '{s1}' ({nq1} qubits) and '{s2}' ({nq2} qubits) due to different qubit counts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e385c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spacy.load('en_core_web_sm')\n",
    "    Tokeniser = SpacyTokeniser()\n",
    "    parser = BobcatParser()\n",
    "    rewriter = Rewriter(['curry', 'prepositional_phrase', 'determiner'])\n",
    "    # ansatz = StronglyEntanglingAnsatz(\n",
    "    # {AtomicType.NOUN: 2, AtomicType.SENTENCE: 1}, \n",
    "    # n_layers=1\n",
    "    # Create Ty objects with the grammatical types as strings   \n",
    "    main_workflow(data_pairs, parser, rewriter, ansatz, Tokeniser)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
