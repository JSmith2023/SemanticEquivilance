{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0a395963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 404 sentences.\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "def load_data(csv_file, sample_fraction=1.0):\n",
    "    \"\"\"Loads Question Pairs from a CSV file\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to csv_file\n",
    "        sample_fraction (float): Fraction of data to sample, default is 1.0\n",
    "    Returns:\n",
    "        tuple: A tuple containing supervised data pairs\n",
    "        returns [],[] on error\n",
    "    \"\"\"\n",
    "    sentences1 = []\n",
    "    sentences2 = []\n",
    "    is_duplicate = []\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8')\n",
    "        #print(\"Column names:\", df.columns)\n",
    "        \n",
    "        if sample_fraction < 1.0:\n",
    "            df = df.sample(frac=sample_fraction, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        sentence1_series = df['question1']\n",
    "        sentence2_series = df['question2']\n",
    "        is_duplicate_series = df['is_duplicate']\n",
    "        \n",
    "        sentences1 = sentence1_series.tolist()\n",
    "        sentences2 = sentence2_series.tolist()\n",
    "        is_duplicate = is_duplicate_series.tolist()\n",
    "        \n",
    "        if len(sentences1) != len(sentences2):\n",
    "            raise ValueError(\"The number of sentences in question1 and question2 do not match.\")\n",
    "        else:\n",
    "            print(f\"Loaded {len(sentences1)} sentences.\")\n",
    "        return sentences1, sentences2, is_duplicate\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Wrong Path\")\n",
    "        return [],[],[]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An {e} Error Occurred\")\n",
    "        return [],[],[]\n",
    "\n",
    "DATA_PATH = r'C:/Users/Jash\\Documents/Research\\Semantic Equivilance\\SemanticEquivilance/question_pairs/questions.csv'\n",
    "sentences1, sentences2, value = load_data(DATA_PATH, sample_fraction=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7815b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "from lambeq import AtomicType, BobcatParser, Rewriter\n",
    "from lambeq.backend.pennylane import to_pennylane as to_qml\n",
    "import random\n",
    "\n",
    "def swap_test(state1_vec, state2_vec, num_qubits, protocol2=False):\n",
    "    \"\"\"\n",
    "    Performs a Quantum Swap Test between two quantum state vectors.\n",
    "\n",
    "    Args:\n",
    "        state1_vec (np.ndarray): The first state vector.\n",
    "        state2_vec (np.ndarray): The second state vector.\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated squared overlap (fidelity) between the two states.\n",
    "    \"\"\"\n",
    "    if 2**num_qubits != len(state1_vec):\n",
    "        raise ValueError(\"State vectors must have a length that is a power of 2.\")\n",
    "\n",
    "    total_qubits = 1 + 2 * num_qubits #1 Ancilla qubit + 2 state qubits\n",
    "\n",
    "    dev = qml.device(\"default.qubit\", wires=total_qubits, shots=1000) # N = 1000 runs of the circuit for statistical significance\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(): #|0 , psi, phi>\n",
    "        # Step 1: Prepare the ancilla qubit in a superposition\n",
    "        qml.Hadamard(wires=0)\n",
    "        print(f\"Comparing: {state1_vec} and {state2_vec}\")\n",
    "        # Step 2: Prepare the two input states\n",
    "        #basis for protocol 1\n",
    "        qml.StatePrep(state1_vec, wires=range(1, 1 + num_qubits), normalize=True)\n",
    "        #basis for protocol 1\n",
    "        qml.StatePrep(state2_vec, wires=range(1 + num_qubits, 1 + 2 * num_qubits))\n",
    "\n",
    "        # Step 3: Apply controlled-SWAP gates\n",
    "        for i in range(num_qubits):\n",
    "            qml.CSWAP(wires=[0, 1 + i, 1 + num_qubits + i]) #selects every register of phi and psi for swap\n",
    "\n",
    "        # Step 4: Apply Hadamard to ancilla\n",
    "        qml.Hadamard(wires=0)\n",
    "        # Step 5: Measure the ancilla qubit\n",
    "        return qml.sample(wires=0)\n",
    "\n",
    "    measurement_results = circuit()\n",
    "    prob_0 = np.sum(measurement_results == 0) / len(measurement_results)\n",
    "    squared_overlap = 2 * prob_0 - 1 #double check this formula we want empirical average\n",
    "\n",
    "    return abs(squared_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambeq_sentence_to_state_vector(sentence, ansatz, parser, rewriter, include_debug_prints=False):\n",
    "    \"\"\"\n",
    "    Converts a natural language sentence into a quantum state vector\n",
    "    using Lambeq's BobcatParser and IQPAnsatz, handling parameterization\n",
    "    via PennyLaneModel.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        ansatz (lambeq.ansatz.Ansatz): The quantum ansatz to apply.\n",
    "        parser (lambeq.parser.Parser): The parser to convert sentence to diagram.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the state vector (np.ndarray) and\n",
    "               the number of qubits (int).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if include_debug_prints:\n",
    "            print(f\"\\n--- Debugging: Sentence '{sentence}' ---\")\n",
    "\n",
    "        # Step 1: Convert sentence to a DisCoPy diagram\n",
    "        diagram = parser.sentence2diagram(sentence)\n",
    "        if include_debug_prints:\n",
    "            print(\"Step 1: Sentence parsed to diagram.\")\n",
    "\n",
    "        # Step 2: Rewrite the diagram\n",
    "        rewritten_diagram = rewriter(diagram)\n",
    "        if include_debug_prints:\n",
    "            print(\"Step 2: Diagram rewritten.\")\n",
    "\n",
    "        # Step 3: Normalize the diagram\n",
    "        normalized_diagram = rewritten_diagram.normal_form()\n",
    "        if include_debug_prints:\n",
    "            print(\"Step 3: Diagram normalized.\")\n",
    "            \n",
    "        # Step 4: Apply the ansatz to the normalized diagram to get a DisCoPy circuit\n",
    "        circuit = ansatz(normalized_diagram)\n",
    "        if include_debug_prints:\n",
    "            print(\"Step 4: Ansatz applied to create DisCoPy circuit.\")\n",
    "\n",
    "        # Step 5: Convert the DisCoPy circuit to a PennyLane circuit object\n",
    "        temp_qml_circuit = to_qml(circuit)\n",
    "        if include_debug_prints:\n",
    "            print(\"Step 5: DisCoPy circuit converted to PennyLane object.\")\n",
    "\n",
    "        num_qubits = temp_qml_circuit._n_qubits\n",
    "        param_structure = temp_qml_circuit._params\n",
    "        \n",
    "        if include_debug_prints:\n",
    "            print(f\"Parameter structure: {param_structure}\")\n",
    "            print(f\"Number of qubits: {num_qubits}, Parameter groups: {len(param_structure)}\")\n",
    "\n",
    "        # Step 6: Create parameters matching the exact structure expected by Lambeq\n",
    "        sentence_hash = abs(hash(sentence))\n",
    "        sentence_seed = (sentence_hash * 17 + len(sentence) * 23) % 10000\n",
    "        random.seed(sentence_seed)\n",
    "        \n",
    "        # Build parameters in the exact same structure as _params\n",
    "        structured_params = []\n",
    "        all_param_values = []\n",
    "        \n",
    "        for param_group in param_structure:\n",
    "            if isinstance(param_group, list) and len(param_group) > 0:\n",
    "                # This parameter group has parameters - create random values for each\n",
    "                group_values = [random.uniform(0.1, 2 * np.pi - 0.1) for _ in param_group]\n",
    "                structured_params.append(group_values)\n",
    "                all_param_values.extend(group_values)\n",
    "            else:\n",
    "                # Empty parameter group\n",
    "                structured_params.append([])\n",
    "            \n",
    "        if include_debug_prints:\n",
    "            print(\"Step 6: Structured parameters generated.\")\n",
    "            print(f\"Sentence hash: {sentence_hash}\")\n",
    "            print(f\"Sentence seed: {sentence_seed}\")\n",
    "            print(f\"Structured params lengths: {[len(group) for group in structured_params]}\")\n",
    "            print(f\"Total parameters: {len(all_param_values)}\")\n",
    "            print(f\"Sample parameter values: {[round(p, 3) for p in all_param_values[:10]] if all_param_values else 'None'}\")\n",
    "            print(f\"Parameter range: {round(min(all_param_values), 3) if all_param_values else 'N/A'} to {round(max(all_param_values), 3) if all_param_values else 'N/A'}\")\n",
    "            \n",
    "        # Step 7: Execute the circuit - \n",
    "        circuit_func = temp_qml_circuit.make_circuit()\n",
    "        \n",
    "        #Create initial state vector\n",
    "        initial_state_vector = np.zeros(2**num_qubits, dtype=np.complex128)\n",
    "        initial_state_vector[initial_state_index] = 1.0\n",
    "        \n",
    "        if include_debug_prints:\n",
    "            print(f\"About to execute circuit with {len(all_param_values)} total parameters\")\n",
    "\n",
    "        if any(len(group) > 0 for group in structured_params):\n",
    "            state_vector = circuit_func(structured_params) #executes QNode with parameters |0> \n",
    "        else:\n",
    "            state_vector = circuit_func([])\n",
    "            #sentences -> sequence of parameters used to define the circuit\n",
    "        # Convert to numpy if it's a tensor\n",
    "        if hasattr(state_vector, 'numpy'):\n",
    "            state_vector = state_vector.numpy()\n",
    "        elif hasattr(state_vector, 'detach'):\n",
    "            state_vector = state_vector.detach().numpy()\n",
    "        \n",
    "        if include_debug_prints:\n",
    "            print(\"Step 7: Circuit executed successfully.\")\n",
    "            print(f\"State vector shape: {state_vector.shape}\")\n",
    "            print(f\"State vector (first few elements): {state_vector[:min(8, len(state_vector))]}\")\n",
    "            \n",
    "        return state_vector, num_qubits\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: Failed to process circuit: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"Returning a default normalized |0> state to allow program continuation.\")\n",
    "        default_state = np.zeros(2, dtype=np.complex128)\n",
    "        default_state[0] = 1.0\n",
    "        return default_state, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e2e208",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlambeq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StronglyEntanglingAnsatz\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      3\u001b[39m     parser = BobcatParser()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\lambeq\\__init__.py:117\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2021-2024 Cambridge Quantum Computing Ltd.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m __all__ = [\n\u001b[32m     16\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m__version_info__\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mMSELoss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    115\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlambeq\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Symbol, lambdify\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlambeq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ansatz, core, rewrite, text2diagram, tokeniser, training\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlambeq\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mansatz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (BaseAnsatz, CircuitAnsatz, IQPAnsatz, MPSAnsatz,\n\u001b[32m    120\u001b[39m                            Sim14Ansatz, Sim15Ansatz, Sim4Ansatz, SpiderAnsatz,\n\u001b[32m    121\u001b[39m                            StronglyEntanglingAnsatz, TensorAnsatz, Sim9Ansatz,\n\u001b[32m    122\u001b[39m                            Sim9CxAnsatz)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\lambeq\\backend\\__init__.py:34\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2021-2024 Cambridge Quantum Computing Ltd.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mBox\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     16\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mCap\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mCategory\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mSymbol\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     32\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mlambdify\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlambeq\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrammar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Box, Cap, Category, Cup, Diagram,\n\u001b[32m     35\u001b[39m                                     Frame, Functor, Id, Spider, Swap, Ty, Word)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlambeq\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lambdify, Symbol\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlambeq\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdrawing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw, draw_equation, to_gif\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\lambeq\\backend\\grammar.py:34\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cast, overload, TYPE_CHECKING\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Self\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlambeq\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fast_deepcopy\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdiscopy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\lambeq\\core\\utils.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, List, TYPE_CHECKING, Union\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcli\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\spacy\\__init__.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthinc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config, prefer_gpu, require_cpu, require_gpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\spacy\\pipeline\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mattributeruler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdep_parser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01medit_tree_lemmatizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EditTreeLemmatizer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\spacy\\pipeline\\attributeruler.py:8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, Iterable, List, Optional, Tuple, Union\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrsly\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Language\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\spacy\\util.py:75\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CudaStream, cupy, importlib_metadata, is_windows\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OLD_MODEL_SHORTCUTS, Errors, Warnings\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbols\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ORTH\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# This lets us add type hints for mypy etc. without causing circular imports\u001b[39;00m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Language, PipeCallable  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:645\u001b[39m, in \u001b[36mparent\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from lambeq import StronglyEntanglingAnsatz\n",
    "if __name__ == \"__main__\":\n",
    "    parser = BobcatParser()\n",
    "    rewriter = Rewriter(['curry', 'prepositional_phrase', 'determiner'])\n",
    "    # Increase the complexity to get more interesting quantum states\n",
    "    \n",
    "# Test with a different ansatz\n",
    "    ansatz = StronglyEntanglingAnsatz(\n",
    "    {AtomicType.NOUN: 2, AtomicType.SENTENCE: 1}, \n",
    "    n_layers=1\n",
    ")\n",
    "\n",
    "    print(\"--- Generating states from sentences ---\")\n",
    "\n",
    "    sentence1 = \"Alice loves the dog that Bob purchased.\"\n",
    "    sentence2 = \"Bob loves the dog that Alice sold.\"\n",
    "    sentence3 = \"The big cat sleeps peacefully.\"\n",
    "    sentence4 = \"The small bird sings loudly.\"\n",
    "\n",
    "    sentences = [sentence1, sentence2, sentence3, sentence4]\n",
    "    state_data = {}\n",
    "    for s_idx, sentence in enumerate(sentences):\n",
    "        try:\n",
    "            #state_vec, num_qubits = lambeq_sentence_to_state_vector(sentence, ansatz, parser, rewriter, include_debug_prints=True)\n",
    "            state_vec, num_qubits = lambeq_sentence_to_state_vector(sentence, ansatz, parser, rewriter)\n",
    "            state_data[sentence] = (state_vec, num_qubits)\n",
    "            print(f\"Sentence {s_idx+1}: '{sentence}'\")\n",
    "            print(f\"Generated state with {num_qubits} qubits\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sentence '{sentence}': {e}\")\n",
    "            state_data[sentence] = (None, None)\n",
    "\n",
    "    print(\"\\n--- Performing Swap Tests ---\")\n",
    "    \n",
    "    # Filter out sentences that did not produce valid states\n",
    "    valid_sentences = [s for s in sentences if state_data[s][0] is not None and state_data[s][1] is not None and state_data[s][1] > 0]\n",
    "\n",
    "    if not valid_sentences:\n",
    "        print(\"No valid multi-qubit states generated. Cannot perform Swap Tests meaningfully.\")\n",
    "    else:\n",
    "        first_num_qubits = state_data[valid_sentences[0]][1]\n",
    "        all_same_qubits = all(state_data[s][1] == first_num_qubits for s in valid_sentences)\n",
    "\n",
    "        if not all_same_qubits:\n",
    "            print(\"\\nWarning: Not all valid sentences resulted in circuits with the same number of qubits.\")\n",
    "            print(\"Swap Test requires states to have the same number of qubits.\")\n",
    "            print(\"Pairs with different qubit counts will be skipped.\")\n",
    "            for s in valid_sentences:\n",
    "                print(f\"  '{s}': {state_data[s][1]} qubits\")\n",
    "\n",
    "        for i in range(len(valid_sentences)):\n",
    "            for j in range(i, len(valid_sentences)):\n",
    "                s1 = valid_sentences[i]\n",
    "                s2 = valid_sentences[j]\n",
    "\n",
    "                vec1, nq1 = state_data[s1]\n",
    "                vec2, nq2 = state_data[s2]\n",
    "\n",
    "                if nq1 == nq2:\n",
    "                    print(f\"\\nSwap Test between '{s1}' and '{s2}':\")\n",
    "                    # Fix: Use nq1 (or nq2, they're equal)\n",
    "                    overlap = swap_test(vec1, vec2, nq1)\n",
    "                    print(f\"Estimated squared overlap: {overlap:.4f}\")\n",
    "                    if s1 == s2:\n",
    "                        print(\" (Expected to be close to 1.0 for identical states)\")\n",
    "                else:\n",
    "                    print(f\"\\nSkipping Swap Test between '{s1}' ({nq1} qubits) and '{s2}' ({nq2} qubits) due to different qubit counts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_test_with_initial_state(state1, state2, n_qubits, initial_state_int=0, shots=1000):\n",
    "    \"\"\"\n",
    "    Performs a swap test between two quantum states with a custom initial state.\n",
    "    \n",
    "    Args:\n",
    "        state1: First quantum state vector\n",
    "        state2: Second quantum state vector  \n",
    "        n_qubits: Number of qubits in each state\n",
    "        initial_state_int: Integer representing initial state (e.g., 5 -> |101⟩ for 3 qubits)\n",
    "        shots: Number of measurements for the swap test\n",
    "    \n",
    "    Returns:\n",
    "        Estimated squared overlap between the states\n",
    "    \"\"\"\n",
    "    import pennylane as qml\n",
    "    \n",
    "    # Create device with extra qubit for ancilla\n",
    "    dev = qml.device('default.qubit', wires=2*n_qubits + 1)\n",
    "    \n",
    "    # Convert integer to binary string\n",
    "    binary_string = format(initial_state_int, f'0{n_qubits}b')\n",
    "    \n",
    "    @qml.qnode(dev)\n",
    "    def swap_test_circuit():\n",
    "        # Prepare initial state for first n qubits by applying X gates\n",
    "        for qubit_idx, bit in enumerate(binary_string):\n",
    "            if bit == '1':\n",
    "                qml.PauliX(wires=qubit_idx)\n",
    "        \n",
    "        # Prepare initial state for second n qubits (same initial state)\n",
    "        for qubit_idx, bit in enumerate(binary_string):\n",
    "            if bit == '1':\n",
    "                qml.PauliX(wires=n_qubits + qubit_idx)\n",
    "        \n",
    "        # Apply the circuits that create state1 and state2\n",
    "        # This is where we'd need to apply your lambeq circuits\n",
    "        # For now, this is a placeholder - you'd replace this with actual circuit application\n",
    "        \n",
    "        # Hadamard on ancilla qubit\n",
    "        qml.Hadamard(wires=2*n_qubits)\n",
    "        \n",
    "        # Controlled swaps between corresponding qubits of the two states\n",
    "        for i in range(n_qubits):\n",
    "            qml.CSWAP(wires=[2*n_qubits, i, n_qubits + i])\n",
    "        \n",
    "        # Final Hadamard on ancilla\n",
    "        qml.Hadamard(wires=2*n_qubits)\n",
    "        \n",
    "        # Measure ancilla qubit\n",
    "        return qml.sample(wires=2*n_qubits)\n",
    "    \n",
    "    # Run the circuit\n",
    "    results = swap_test_circuit()\n",
    "    \n",
    "    # Calculate probability of measuring 0 on ancilla\n",
    "    prob_0 = np.mean(results == 0)\n",
    "    \n",
    "    # The squared overlap is related to this probability\n",
    "    squared_overlap = 2 * prob_0 - 1\n",
    "    \n",
    "    return max(0, squared_overlap)  # Ensure non-negative due to sampling noise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = BobcatParser()\n",
    "    rewriter = Rewriter(['curry', 'prepositional_phrase', 'determiner'])\n",
    "    \n",
    "    from lambeq import StronglyEntanglingAnsatz \n",
    "\n",
    "    # Test with a different ansatz\n",
    "    ansatz = StronglyEntanglingAnsatz(\n",
    "        {AtomicType.NOUN: 2, AtomicType.SENTENCE: 1}, \n",
    "        n_layers=2\n",
    "    )\n",
    "\n",
    "    print(\"--- Generating states from sentences with varying initial qubit states ---\")\n",
    "\n",
    "    sentence1 = \"Alice loves the dog that Bob purchased.\"\n",
    "    sentence2 = \"Bob loves the dog that Alice sold.\"\n",
    "    sentence3 = \"The big cat sleeps peacefully.\"\n",
    "    sentence4 = \"The small bird sings loudly.\"\n",
    "\n",
    "    sentences = [sentence1, sentence2, sentence3, sentence4]\n",
    "    \n",
    "    # First, determine the number of qubits by processing one sentence\n",
    "    sample_sentence = sentences[0]\n",
    "    try:\n",
    "        sample_state_vec, sample_num_qubits = lambeq_sentence_to_state_vector(sample_sentence, ansatz, parser, rewriter)\n",
    "        num_qubits = sample_num_qubits\n",
    "        print(f\"Circuits use {num_qubits} qubits\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing sample circuit: {e}\")\n",
    "        num_qubits = 4  # Default fallback\n",
    "    \n",
    "    max_initial_states = 2**num_qubits\n",
    "    print(f\"Will test {max_initial_states} different initial states (0 to {max_initial_states-1})\")\n",
    "    \n",
    "    all_state_data = {}\n",
    "    \n",
    "    # Loop through different initial states using integers\n",
    "    num_states_to_test = min(8, max_initial_states)  # Limit for demo\n",
    "    \n",
    "    for initial_state_int in range(num_states_to_test):\n",
    "        # Convert to binary string for display\n",
    "        binary_string = format(initial_state_int, f'0{num_qubits}b')\n",
    "        \n",
    "        print(f\"\\n--- Initial State {initial_state_int} -> |{binary_string}⟩ ---\")\n",
    "        \n",
    "        combo_states = {}\n",
    "        \n",
    "        # Process each sentence with this initial state\n",
    "        for s_idx, sentence in enumerate(sentences):\n",
    "            try:\n",
    "                # Create a modified version of your lambeq function that prepares initial state\n",
    "                import pennylane as qml\n",
    "                \n",
    "                # Get the original circuit structure\n",
    "                diagram = parser.sentence2diagram(sentence)\n",
    "                rewritten_diagram = rewriter(diagram)\n",
    "                normalized_diagram = rewritten_diagram.normal_form()\n",
    "                circuit = ansatz(normalized_diagram)\n",
    "                temp_qml_circuit = to_qml(circuit)\n",
    "                \n",
    "                param_structure = temp_qml_circuit._params\n",
    "                \n",
    "                # Generate same parameters as original function\n",
    "                sentence_hash = abs(hash(sentence))\n",
    "                sentence_seed = (sentence_hash * 17 + len(sentence) * 23) % 10000\n",
    "                random.seed(sentence_seed)\n",
    "                \n",
    "                structured_params = []\n",
    "                for param_group in param_structure:\n",
    "                    if isinstance(param_group, list) and len(param_group) > 0:\n",
    "                        group_values = [random.uniform(0.1, 2 * np.pi - 0.1) for _ in param_group]\n",
    "                        structured_params.append(group_values)\n",
    "                    else:\n",
    "                        structured_params.append([])\n",
    "                \n",
    "                # Create new device and circuit with initial state preparation\n",
    "                dev = qml.device('default.qubit', wires=num_qubits)\n",
    "                \n",
    "                @qml.qnode(dev)\n",
    "                def circuit_with_initial_state(*params):\n",
    "                    # Step 1: Prepare initial state using X gates\n",
    "                    binary_string = format(initial_state_int, f'0{num_qubits}b')\n",
    "                    for qubit_idx, bit in enumerate(binary_string):\n",
    "                        if bit == '1':\n",
    "                            qml.PauliX(wires=qubit_idx)\n",
    "                    \n",
    "                    # Step 2: Apply original circuit operations\n",
    "                    # We need to reconstruct the circuit operations from temp_qml_circuit\n",
    "                    # This is a simplified approach - you might need to adapt based on your setup\n",
    "                    \n",
    "                    # For now, let's apply the original circuit function on top of our prepared state\n",
    "                    # This requires accessing the internal structure of temp_qml_circuit\n",
    "                    \n",
    "                    return qml.state()\n",
    "                \n",
    "                # Execute circuit with prepared initial state\n",
    "                if any(len(group) > 0 for group in structured_params):\n",
    "                    flat_params = [param for group in structured_params for param in group]\n",
    "                    state_vector = circuit_with_initial_state(*flat_params)\n",
    "                else:\n",
    "                    state_vector = circuit_with_initial_state()\n",
    "                \n",
    "                # Convert to numpy if needed\n",
    "                if hasattr(state_vector, 'numpy'):\n",
    "                    state_vector = state_vector.numpy()\n",
    "                elif hasattr(state_vector, 'detach'):\n",
    "                    state_vector = state_vector.detach().numpy()\n",
    "                \n",
    "                combo_states[sentence] = (state_vector, num_qubits)\n",
    "                print(f\"  Sentence {s_idx+1}: '{sentence[:30]}...' -> processed\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing sentence '{sentence[:30]}...': {e}\")\n",
    "                # Fallback to original method without initial state preparation\n",
    "                try:\n",
    "                    fallback_state, fallback_qubits = lambeq_sentence_to_state_vector(sentence, ansatz, parser, rewriter)\n",
    "                    combo_states[sentence] = (fallback_state, fallback_qubits)\n",
    "                    print(f\"  Fallback: Used default |000...0⟩ initial state\")\n",
    "                except:\n",
    "                    combo_states[sentence] = (None, None)\n",
    "        \n",
    "        # Store results for this initial state\n",
    "        all_state_data[initial_state_int] = combo_states\n",
    "\n",
    "    print(\"\\n--- Performing Swap Tests Across Initial States ---\")\n",
    "    \n",
    "    # Compare states from different initial conditions\n",
    "    initial_state_ints = list(all_state_data.keys())\n",
    "    \n",
    "    # For each sentence, compare across different initial states\n",
    "    for sentence in sentences:\n",
    "        print(f\"\\n=== Analyzing '{sentence[:30]}...' across initial states ===\")\n",
    "        \n",
    "        # Get valid states for this sentence across all initial states\n",
    "        valid_states = []\n",
    "        for init_int in initial_state_ints:\n",
    "            if sentence in all_state_data[init_int]:\n",
    "                state_vec, nq = all_state_data[init_int][sentence]\n",
    "                if state_vec is not None and nq is not None:\n",
    "                    valid_states.append((init_int, state_vec, nq))\n",
    "        \n",
    "        if len(valid_states) < 2:\n",
    "            print(\"  Not enough valid states for comparison\")\n",
    "            continue\n",
    "        \n",
    "        # Compare pairs of initial states\n",
    "        for i in range(len(valid_states)):\n",
    "            for j in range(i+1, min(i+3, len(valid_states))):  # Limit comparisons\n",
    "                init_int1, vec1, nq1 = valid_states[i]\n",
    "                init_int2, vec2, nq2 = valid_states[j]\n",
    "                \n",
    "                # Convert to binary for display\n",
    "                binary1 = format(init_int1, f'0{num_qubits}b')\n",
    "                binary2 = format(init_int2, f'0{num_qubits}b')\n",
    "                \n",
    "                # Use regular swap test since states already have initial conditions applied\n",
    "                overlap = swap_test(vec1, vec2, nq1)\n",
    "                \n",
    "                # Calculate Hamming distance\n",
    "                hamming_dist = sum(c1 != c2 for c1, c2 in zip(binary1, binary2))\n",
    "                \n",
    "                print(f\"  |{binary1}⟩ vs |{binary2}⟩: Hamming={hamming_dist}, Overlap={overlap:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Initial State Impact Analysis ---\")\n",
    "    \n",
    "    # Analyze how much each initial state changes the results\n",
    "    for sentence in sentences:\n",
    "        print(f\"\\nSentence: '{sentence[:40]}...'\")\n",
    "        \n",
    "        # Compare all states to the |000...0⟩ baseline\n",
    "        baseline_int = 0\n",
    "        if baseline_int in all_state_data and sentence in all_state_data[baseline_int]:\n",
    "            baseline_state = all_state_data[baseline_int][sentence]\n",
    "            if baseline_state[0] is not None:\n",
    "                overlaps = []\n",
    "                \n",
    "                for init_int in initial_state_ints[1:]:  # Skip baseline\n",
    "                    if sentence in all_state_data[init_int]:\n",
    "                        comp_state = all_state_data[init_int][sentence]\n",
    "                        if comp_state[0] is not None:\n",
    "                            overlap = swap_test(baseline_state[0], comp_state[0], baseline_state[1])\n",
    "                            overlaps.append(overlap)\n",
    "                            \n",
    "                            # Show individual comparisons\n",
    "                            binary_str = format(init_int, f'0{num_qubits}b')\n",
    "                            print(f\"  |000...0⟩ vs |{binary_str}⟩: {overlap:.4f}\")\n",
    "                \n",
    "                if overlaps:\n",
    "                    avg_overlap = np.mean(overlaps)\n",
    "                    std_overlap = np.std(overlaps)\n",
    "                    print(f\"  Average overlap: {avg_overlap:.4f} ± {std_overlap:.4f}\")\n",
    "                    print(f\"  Sensitivity: {'High' if avg_overlap < 0.7 else 'Medium' if avg_overlap < 0.9 else 'Low'}\")\n",
    "\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    print(\"Analysis shows how different initial qubit states affect quantum sentence representations.\")\n",
    "    print(\"Lower overlap values indicate higher sensitivity to initial conditions.\")\n",
    "    \n",
    "    print(\"\\n--- Analysis Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
