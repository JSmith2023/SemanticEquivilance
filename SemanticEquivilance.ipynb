{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a395963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 404 sentences.\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "def load_data(csv_file, sample_fraction=1.0):\n",
    "    \"\"\"Loads Question Pairs from a CSV file\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to csv_file\n",
    "        sample_fraction (float): Fraction of data to sample, default is 1.0\n",
    "    Returns:\n",
    "        tuple: A tuple containing supervised data pairs\n",
    "        returns [],[] on error\n",
    "    \"\"\"\n",
    "    sentences1 = []\n",
    "    sentences2 = []\n",
    "    is_duplicate = []\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8')\n",
    "        #print(\"Column names:\", df.columns)\n",
    "        \n",
    "        if sample_fraction < 1.0:\n",
    "            df = df.sample(frac=sample_fraction, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        sentence1_series = df['question1']\n",
    "        sentence2_series = df['question2']\n",
    "        is_duplicate_series = df['is_duplicate']\n",
    "        \n",
    "        sentences1 = sentence1_series.tolist()\n",
    "        sentences2 = sentence2_series.tolist()\n",
    "        is_duplicate = is_duplicate_series.tolist()\n",
    "        \n",
    "        if len(sentences1) != len(sentences2):\n",
    "            raise ValueError(\"The number of sentences in question1 and question2 do not match.\")\n",
    "        else:\n",
    "            print(f\"Loaded {len(sentences1)} sentences.\")\n",
    "        return sentences1, sentences2, is_duplicate\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Wrong Path\")\n",
    "        return [],[],[]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An {e} Error Occurred\")\n",
    "        return [],[],[]\n",
    "\n",
    "DATA_PATH = r'C:/Users/Jash\\Documents/Research\\Semantic Equivilance\\SemanticEquivilance/question_pairs/questions.csv'\n",
    "sentences1, sentences2, value = load_data(DATA_PATH, sample_fraction=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7815b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating states from sentences ---\n",
      "Warning: Alice loves Bob. resulted in a 0-qubit circuit. No state vector can be generated.\n",
      "Sentence 1: 'Alice loves Bob.'\n",
      "Number of qubits for state 1: 1\n",
      "State vector 1 shape: (2,)\n",
      "Warning: Bob loves Alice. resulted in a 0-qubit circuit. No state vector can be generated.\n",
      "\n",
      "Sentence 2: 'Bob loves Alice.'\n",
      "Number of qubits for state 2: 1\n",
      "State vector 2 shape: (2,)\n",
      "Warning: The cat sits. resulted in a 0-qubit circuit. No state vector can be generated.\n",
      "\n",
      "Sentence 3: 'The cat sits.'\n",
      "Number of qubits for state 3: 1\n",
      "State vector 3 shape: (2,)\n",
      "\n",
      "--- Performing Swap Tests ---\n",
      "Swap Test between 'Alice loves Bob.' and 'Bob loves Alice.':\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pennylane' has no attribute 'QubitStateVector'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 192\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# Swap Test between similar sentences\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSwap Test between \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m overlap_sim = \u001b[43mswap_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate1_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate2_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEstimated squared overlap: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverlap_sim\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# Expect overlap to be relatively high for semantically similar sentences.\u001b[39;00m\n\u001b[32m    195\u001b[39m \n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# Swap Test between dissimilar sentences\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mswap_test\u001b[39m\u001b[34m(state1_vec, state2_vec)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m qml.sample(wires=\u001b[32m0\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Execute the circuit\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m measurement_results = \u001b[43mcircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Calculate the probability of measuring 0 on the ancilla qubit\u001b[39;00m\n\u001b[32m     79\u001b[39m prob_0 = np.sum(measurement_results == \u001b[32m0\u001b[39m) / \u001b[38;5;28mlen\u001b[39m(measurement_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:922\u001b[39m, in \u001b[36mQNode.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:890\u001b[39m, in \u001b[36mQNode._impl_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_impl_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs) -> Result:\n\u001b[32m    888\u001b[39m \n\u001b[32m    889\u001b[39m     \u001b[38;5;66;03m# construct the tape\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m     tape = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    892\u001b[39m     \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[32m    893\u001b[39m     \u001b[38;5;28mself\u001b[39m._transform_program.set_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\pennylane\\logging\\decorators.py:61\u001b[39m, in \u001b[36mlog_string_debug_func.<locals>.wrapper_entry\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m     s_caller = \u001b[33m\"\u001b[39m\u001b[33m::L\u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     55\u001b[39m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect.getouterframes(inspect.currentframe(), \u001b[32m2\u001b[39m)[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m:\u001b[32m3\u001b[39m]]\n\u001b[32m     56\u001b[39m     )\n\u001b[32m     57\u001b[39m     lgr.debug(\n\u001b[32m     58\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m         **_debug_log_kwargs,\n\u001b[32m     60\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:876\u001b[39m, in \u001b[36mQNode.construct\u001b[39m\u001b[34m(self, args, kwargs)\u001b[39m\n\u001b[32m    874\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pldb_device_manager(\u001b[38;5;28mself\u001b[39m.device):\n\u001b[32m    875\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m AnnotatedQueue() \u001b[38;5;28;01mas\u001b[39;00m q:\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m         \u001b[38;5;28mself\u001b[39m._qfunc_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    878\u001b[39m tape = QuantumScript.from_queue(q, shots)\n\u001b[32m    880\u001b[39m params = tape.get_parameters(trainable_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mswap_test.<locals>.circuit\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     56\u001b[39m qml.Hadamard(wires=\u001b[32m0\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Step 2: Encode the two states onto their respective wire registers\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Wires 1 to num_qubits for state1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mqml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mQubitStateVector\u001b[49m(state1_vec, wires=\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m + num_qubits))\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Wires (1 + num_qubits) to (1 + 2 * num_qubits) for state2\u001b[39;00m\n\u001b[32m     62\u001b[39m qml.QubitStateVector(state2_vec, wires=\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m + num_qubits, \u001b[32m1\u001b[39m + \u001b[32m2\u001b[39m * num_qubits))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jash\\Documents\\Research\\Semantic Equivilance\\.venv\\Lib\\site-packages\\pennylane\\__init__.py:211\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mplugin_devices\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pennylane.devices.device_constructor.plugin_devices\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpennylane\u001b[39m\u001b[33m'\u001b[39m\u001b[33m has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'pennylane' has no attribute 'QubitStateVector'"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "from lambeq import AtomicType, BobcatParser, IQPAnsatz, PennyLaneModel, Symbol\n",
    "from discopy.quantum import Circuit\n",
    "\n",
    "def get_circuit_state_vector(qml_circuit_func, num_wires, params=None):\n",
    "    \"\"\"\n",
    "    Executes a PennyLane QNode and returns the state vector.\n",
    "\n",
    "    Args:\n",
    "        qml_circuit_func (callable): The PennyLane QNode function.\n",
    "        num_wires (int): The number of wires in the circuit.\n",
    "        params (dict, optional): A dictionary of parameters for the QNode. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The state vector produced by the circuit.\n",
    "    \"\"\"\n",
    "    dev = qml.device(\"default.qubit\", wires=num_wires)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def state_vector_circuit():\n",
    "        if params is not None:\n",
    "            qml_circuit_func(params)\n",
    "        else:\n",
    "            qml_circuit_func()\n",
    "        return qml.state()\n",
    "\n",
    "    return state_vector_circuit()\n",
    "\n",
    "\n",
    "def swap_test(state1_vec, state2_vec):\n",
    "    \"\"\"\n",
    "    Implements the Swap Test to estimate the overlap between two quantum states.\n",
    "\n",
    "    Args:\n",
    "        state1_vec (np.ndarray): The state vector of the first quantum state.\n",
    "        state2_vec (np.ndarray): The state vector of the second quantum state.\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated squared overlap |<psi|phi>|^2.\n",
    "    \"\"\"\n",
    "    # Determine the number of qubits required for each state\n",
    "    num_qubits = int(np.log2(len(state1_vec)))\n",
    "    if 2**num_qubits != len(state1_vec):\n",
    "        raise ValueError(\"State vectors must have a length that is a power of 2.\")\n",
    "\n",
    "    # Total qubits: 1 for ancilla + num_qubits for state1 + num_qubits for state2\n",
    "    total_qubits = 1 + 2 * num_qubits\n",
    "\n",
    "    # Define the device for the swap test\n",
    "    dev = qml.device(\"default.qubit\", wires=total_qubits, shots=1000)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit():\n",
    "        # Step 1: Initialize the ancilla qubit in a superposition\n",
    "        qml.Hadamard(wires=0)\n",
    "\n",
    "        # Step 2: Encode the two states onto their respective wire registers\n",
    "        # Wires 1 to num_qubits for state1\n",
    "        qml.StatePrep(state1_vec, wires=range(1, 1 + num_qubits))\n",
    "        # Wires (1 + num_qubits) to (1 + 2 * num_qubits) for state2\n",
    "        qml.StatePrep(state2_vec, wires=range(1 + num_qubits, 1 + 2 * num_qubits))\n",
    "\n",
    "        # Step 3: Apply controlled-SWAP operations\n",
    "        # The ancilla (wire 0) controls the SWAP between corresponding qubits of state1 and state2\n",
    "        for i in range(num_qubits):\n",
    "            qml.CSWAP(wires=[0, 1 + i, 1 + num_qubits + i])\n",
    "\n",
    "        # Step 4: Apply Hadamard to the ancilla qubit\n",
    "        qml.Hadamard(wires=0)\n",
    "\n",
    "        # Step 5: Measure the ancilla qubit\n",
    "        return qml.sample(wires=0)\n",
    "\n",
    "    # Execute the circuit\n",
    "    measurement_results = circuit()\n",
    "\n",
    "    # Calculate the probability of measuring 0 on the ancilla qubit\n",
    "    prob_0 = np.sum(measurement_results == 0) / len(measurement_results)\n",
    "\n",
    "    # The probability of measuring 0 on the ancilla qubit is P(0) = 0.5 * (1 + |<psi|phi>|^2)\n",
    "    # Therefore, |<psi|phi>|^2 = 2 * P(0) - 1\n",
    "    squared_overlap = 2 * prob_0 - 1\n",
    "\n",
    "    return squared_overlap\n",
    "\n",
    "def lambeq_sentence_to_state_vector(sentence, ansatz, parser):\n",
    "    \"\"\"\n",
    "    Converts a sentence to a quantum circuit using lambeq and returns its state vector.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        ansatz (lambeq.ansatz.Ansatz): The ansatz to convert the diagram to a circuit.\n",
    "        parser (lambeq.parser.Parser): The parser to convert the sentence to a diagram.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The state vector generated by the lambeq circuit.\n",
    "        int: The number of qubits in the generated circuit.\n",
    "    \"\"\"\n",
    "    diagram = parser.sentence2diagram(sentence)\n",
    "    circuit = ansatz(diagram)\n",
    "\n",
    "    # lambeq circuits often contain sympy Symbols as parameters.\n",
    "    # We need to assign numerical values to these for PennyLane.\n",
    "    # For a simple overlap test, we can just set them to 0 or random values.\n",
    "    # In a real QNLP application, these would be trained parameters.\n",
    "\n",
    "    # Extract free symbols (parameters) from the circuit\n",
    "    free_symbols = sorted(list(circuit.free_symbols), key=str)\n",
    "\n",
    "    # Create a PennyLane model to get the state vector\n",
    "    # We need to explicitly define the QNode for PennyLane to get the state vector.\n",
    "    # lambeq's PennyLaneModel often returns probabilities, so we'll build a custom QNode.\n",
    "\n",
    "    num_qubits = len(circuit.dom)\n",
    "\n",
    "    if num_qubits == 0:\n",
    "        print(f\"Warning: {sentence} resulted in a 0-qubit circuit. No state vector can be generated.\")\n",
    "        return np.array([1,0]), 1 #Default to |0> for a single qubit \n",
    "    if not free_symbols:\n",
    "        # If there are no parameters, the circuit is fixed.\n",
    "        # We can just convert the DisCoPy circuit to a PennyLane QNode directly.\n",
    "        def qml_circuit_fixed():\n",
    "            qml.from_discopy(circuit)\n",
    "        state_vec = get_circuit_state_vector(qml_circuit_fixed, num_qubits)\n",
    "    else:\n",
    "        # If there are parameters, we need to provide a parameter mapping.\n",
    "        # For demonstration, we'll map them to arbitrary values (e.g., 0).\n",
    "        subs_map = [(sym, 0.0) for sym in free_symbols]\n",
    "\n",
    "        # Substitute parameters in the DisCoPy circuit\n",
    "        bound_circuit = circuit.subs(subs_map)\n",
    "\n",
    "        def qml_circuit_parametric():\n",
    "            qml.from_discopy(bound_circuit) # This will apply the operations from the bound circuit\n",
    "        state_vec = get_circuit_state_vector(qml_circuit_parametric, num_qubits)\n",
    "\n",
    "    # Normalize the state vector if it's not already\n",
    "    state_vec = state_vec / np.linalg.norm(state_vec)\n",
    "\n",
    "    return state_vec, num_qubits\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize lambeq components\n",
    "    parser = BobcatParser()\n",
    "    # IQPAnsatz is a common choice for QNLP\n",
    "    # The AtomicType.NOUN: 1 means that each noun will be represented by 1 qubit.\n",
    "    # AtomicType.SENTENCE: 1 means the output sentence type will be 1 qubit.\n",
    "    ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1}, n_layers=1)\n",
    "\n",
    "    print(\"--- Generating states from sentences ---\")\n",
    "\n",
    "    # Sentence 1\n",
    "    sentence1 = \"Alice loves Bob.\"\n",
    "    state1_vec, num_qubits1 = lambeq_sentence_to_state_vector(sentence1, ansatz, parser)\n",
    "    print(f\"Sentence 1: '{sentence1}'\")\n",
    "    print(f\"Number of qubits for state 1: {num_qubits1}\")\n",
    "    print(f\"State vector 1 shape: {state1_vec.shape}\")\n",
    "\n",
    "    # Sentence 2 (similar meaning to sentence 1)\n",
    "    sentence2 = \"Bob loves Alice.\"\n",
    "    state2_vec, num_qubits2 = lambeq_sentence_to_state_vector(sentence2, ansatz, parser)\n",
    "    print(f\"\\nSentence 2: '{sentence2}'\")\n",
    "    print(f\"Number of qubits for state 2: {num_qubits2}\")\n",
    "    print(f\"State vector 2 shape: {state2_vec.shape}\")\n",
    "\n",
    "    # Sentence 3 (different meaning)\n",
    "    sentence3 = \"The cat sits.\"\n",
    "    state3_vec, num_qubits3 = lambeq_sentence_to_state_vector(sentence3, ansatz, parser)\n",
    "    print(f\"\\nSentence 3: '{sentence3}'\")\n",
    "    print(f\"Number of qubits for state 3: {num_qubits3}\")\n",
    "    print(f\"State vector 3 shape: {state3_vec.shape}\")\n",
    "\n",
    "    # Ensure states have the same number of qubits for the Swap Test\n",
    "    if num_qubits1 != num_qubits2 or num_qubits1 != num_qubits3:\n",
    "        # This is a common issue when different sentences produce circuits with different numbers of wires.\n",
    "        # lambeq's IQPAnsatz generally tries to keep the number of qubits consistent for a given AtomicType mapping.\n",
    "        # However, complex sentences or different ansaetze might lead to varying qubit counts.\n",
    "        # For the Swap Test, the input states MUST have the same number of qubits.\n",
    "        print(\"\\nWarning: Sentences resulted in circuits with different numbers of qubits.\")\n",
    "        print(\"Swap Test requires states to have the same number of qubits.\")\n",
    "        print(\"Please choose sentences that result in the same number of output qubits.\")\n",
    "        print(\"For instance, using very simple sentences or ensuring the 'n_single_qubit_params' and 'n_layers' are carefully chosen.\")\n",
    "        # You might need to pad the smaller state vector with zeros if the meaning allows for it,\n",
    "        # or use a different ansatz/parser that guarantees consistent qubit counts.\n",
    "    else:\n",
    "        print(\"\\n--- Performing Swap Tests ---\")\n",
    "\n",
    "        # Swap Test between similar sentences\n",
    "        print(f\"Swap Test between '{sentence1}' and '{sentence2}':\")\n",
    "        overlap_sim = swap_test(state1_vec, state2_vec)\n",
    "        print(f\"Estimated squared overlap: {overlap_sim:.4f}\")\n",
    "        # Expect overlap to be relatively high for semantically similar sentences.\n",
    "\n",
    "        # Swap Test between dissimilar sentences\n",
    "        print(f\"\\nSwap Test between '{sentence1}' and '{sentence3}':\")\n",
    "        overlap_dissim = swap_test(state1_vec, state3_vec)\n",
    "        print(f\"Estimated squared overlap: {overlap_dissim:.4f}\")\n",
    "        # Expect overlap to be relatively low for semantically dissimilar sentences.\n",
    "\n",
    "        # Swap Test between identical circuits (should be close to 1)\n",
    "        print(f\"\\nSwap Test between '{sentence1}' and '{sentence1}':\")\n",
    "        overlap_identical = swap_test(state1_vec, state1_vec)\n",
    "        print(f\"Estimated squared overlap: {overlap_identical:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54dcd9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 processes.\n"
     ]
    }
   ],
   "source": [
    "from lambeq import BobcatParser, SpacyTokeniser, Rewriter, AtomicType, IQPAnsatz\n",
    "from lambeq.backend.grammar import Diagram as grammatical_diagram\n",
    "from lambeq.backend.quantum import Diagram as quantum_circuit\n",
    "from typing import Optional\n",
    "import os, time, multiprocessing\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\" #environment variable for multithreading\n",
    "\n",
    "#Global data sequencing variables\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "print(f\"Using {num_processes} processes.\")\n",
    "\n",
    "_tokenizer = None\n",
    "_parser = None\n",
    "_rewriter = None\n",
    "_ansatz = None\n",
    "\n",
    "def _initializer():\n",
    "    global _tokenizer, _parser, _rewriter, _ansatz\n",
    "    _tokenizer = SpacyTokeniser()  # Initialize tokenizer\n",
    "    _parser = BobcatParser(verbose=\"suppress\")  # Initialize parser \n",
    "    _rewriter = Rewriter(['prepositional_phrase', 'determiner'])  # Initialize rewriter\n",
    "    _ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1}, n_layers=2, n_single_qubit_params=3)  # Initialize ansatz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ee7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(sentence: str, tokeniser, parser, rewriter, ansatz) -> Optional[grammatical_diagram]:\n",
    "    \"\"\"Process a single sentence to a diagram.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): Sentence to be converted to a diagram.\n",
    "\n",
    "    Returns:\n",
    "        Optional[quantum_circuit]: Either returns a diagram or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sentence = sentence.strip().lower()\n",
    "        tokens = tokeniser.tokenise_sentence(sentence)\n",
    "        diagram = parser.sentence2diagram(tokens, tokenised=True) #remove tokenization? might remove some errors \n",
    "        if diagram is not None:\n",
    "            diagram = rewriter(diagram)\n",
    "            normalised_diagram = diagram.normal_form()\n",
    "            curry_functor = Rewriter(['curry'])\n",
    "            curried_diagram = curry_functor(normalised_diagram)\n",
    "            circuit = ansatz(curried_diagram)\n",
    "            return circuit\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentence {sentence}\")\n",
    "        return None\n",
    "def _process_data_for_pool(sentence: str) -> Optional[grammatical_diagram]:\n",
    "    \"\"\"Process a single sentence for the multiprocessing pool.\"\"\"\n",
    "    return process_data(sentence, _tokenizer, _parser, _rewriter, _ansatz)\n",
    "\n",
    "def process_sentences(sentences: list[str]) -> list[Optional[grammatical_diagram]]:\n",
    "    \"\"\"Process sentences in parallel using multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        sentences (list[str]): List of sentences to be processed.\n",
    "\n",
    "    Returns:\n",
    "        list[Optional[quantum_circuit]]: List of processed diagrams or None for errors.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    batch_size = 50\n",
    "    with multiprocessing.Pool(processes=num_processes, initializer=_initializer) as pool:\n",
    "        for i in range(0, len(sentences), batch_size):\n",
    "            batch = sentences[i:i + batch_size]\n",
    "            print(f\"Processing batch {i // batch_size + 1} with {len(batch)} sentences.\")\n",
    "            current_batch = sentences[i:i + batch_size]\n",
    "            \n",
    "            batch_results = pool.map(_process_data_for_pool, current_batch)\n",
    "        # Collect results from all batches\n",
    "        #results = pool.map(_process_data_for_pool, sentences)\n",
    "        end_time = time.time()\n",
    "        print(f\"Processed {len(sentences)} sentences in {end_time - start_time:.4f} seconds.\")\n",
    "    return batch_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
